\chapter{Modulação de comportamento como parte do modelo de negócio das
plataformas de mídias sociais}

\begin{flushright}
\emph{Débora Machado}
\end{flushright}

Nos últimos cinco anos, ``dados são o novo petróleo'' parece ter sido a
frase mais repetida por \versal{CEO}s de grandes empresas de tecnologia,
palestrantes em eventos para start ups e textos em revistas
especializadas em tecnologia do mundo inteiro. Não por acaso.
Atualmente, o mercado de dados pessoais representa grande parte da
economia informacional. ``Gerado pelas identidades e comportamentos,
pelos indivíduos e suas ações em redes digitais, os dados pessoais são a
moeda paga pelo uso gratuito de plataformas, sites e serviços online''
(\versal{SILVEIRA; AVELINO; SOUZA}, 2016, p. 220). E assim como os ambientalistas
seguem a anos nos alertando das consequências do uso exacerbado dos
combustíveis fósseis, os pesquisadores que estudam as intersecções de
tecnologia e sociedade voltam"-se cada vez mais para as consequências
sociais da exploração do Big Data pelas grandes empresas na corrida pela
extração desses bens imateriais.

Diversos autores apontam a capacidade de orientar, modificar ou modular
o comportamento do usuário que utiliza uma tecnologia como o objetivo
final e o verdadeiro ouro negro no processo da coleta e análise de dados
(\versal{BRUNO}, 2013; \versal{PASQUELE}, 2014; \versal{ROUVROY}, 2015; \versal{SILVEIRA}, 2017). Se os dados são o novo petróleo, a modulação do comportamento humano seria o
produto de luxo, feito sob medida, já na ponta final da cadeia de
produção. E para entender como essa modulação se dá, é necessário antes
compreender algumas rupturas que possibilitaram que esse processo fosse
criado, automatizado e monetizado.

Uma das maiores mudanças que a Sociedade em Rede (\versal{CASTELLS}, 2013)
proporcionou, e a popularização das plataformas de mídias sociais
intensificou, foi a possibilidade de todo usuário ser também um produtor
de conteúdo. Isso transformou a situação de escassez da mídia de massa
em uma abundância de dados e conexões, possível somente em uma rede
distribuída como a internet. Após o ano 2000, tanto a capacidade dos
computadores quanto a quantidade de dados armazenados na rede
cresceramexponencialmente. Entre 1986 e 2016 estima"-se um crescimento de
31\% ao ano na capacidade tecnológica mundial para armazenar informação,
passando de 2.6 exabytes para 4.6 zettabytes (\versal{HILBERT}, 2015). Assim como
com o aumento da quantidade de livros escritos no século \versal{XVI} veio a
necessidade de criação de livros de referências, atlas, enciclopédias e
bibliotecas organizadas de forma com que as informações relevantes
pudessem ser acessadas mais facilmente, encontrar caminhos na rede sem o
uso de softwares e algoritmos que filtrem as informações antes de
apresentá"-las ao usuário tornou"-se uma tarefa difícil (\versal{WELLMON}, 2012).

Algoritmos podem ser descritos como uma série de instruções delegadas a
uma máquina para resolver problemas pré"-definidos. São processos
codificados para transformar dados de entrada em uma saída desejada, com
base em cálculos especificados e estão presentes em praticamente todas
as funções que executamos na rede. Nos mecanismos de busca, eles ajudam
a navegar dentre o universo de informação presente na web. Nos sites de
compras, eles sugerem produtos que podem ser relevantes para clientes
que já efetuaram uma determinada compra. Dentro na nossa caixa de
e"-mail, eles ajudam a definir o que é importante e o que é spam. São os
algoritmos que definem quais informações são relevantes e quais não
precisam ser exibidas (\versal{GILLESPIE}, 2014).

No entanto, os algoritmos não possuem uma função meramente
organizacional ou de facilitação do uso dessas plataformas pelos
usuários. Eles vão além, possibilitam também a coleta e a análise
massiva e automatizada de dados, o que os tornou tecnologias essenciais
para o modelo de negócio das principais plataformas digitais utilizadas
nos últimos anos.

Os algoritmos costumam ser entendidos como ``preocupações estritamente
racionais, que juntam as certezas da matemática com a objetividade da
tecnologia''\footnote{\emph{``Algorithms per se are supposed to be strictly
  rational concerns, marrying the certainties of mathematics with the
  objectivity of technology''} (\versal{SEAVER}, 2013, p. 2, tradução nossa).}.
Contudo, esses processos nunca são puramente abstratos e matemáticos.
Apesar da tentativa dos programadores de manter um grau de objetividade,
distanciando"-se de qualquer tipo de influência -- inclusive cultural ou
refletindo contextos locais -- o processo de tradução da tarefa ou
conhecimento para um sistema algorítmico não se mantém imune a essas
interferências (\emph{Ibid}.). Algoritmos são criados para propósitos que, na
maioria das vezes estão longe de serem neutros: ``para criar valor e
capital, para impulsionar um comportamento e estruturar preferências de
uma certa forma; e para identificar, selecionar e classificar
pessoas'' (\versal{KITCHIN}, 2017, p. 18, tradução nossa). Essa dualidade no
entendimento sobre as funções desses sistemas é intencional e vantajosa
para o mercado. Para que tanto os usuários que utilizam a plataforma
para consumir informação e se conectar quanto aqueles que a utilizam
para impulsionar conteúdo e disponibilizar anúncios tenham um certo grau
de confiança na tecnologia utilizada, é necessário que essa seja
entendida como uma ferramenta que realiza uma avaliação neutra para quem
consome seus resultados, e vendidos como uma ferramenta de promoção
seletiva a anunciantes em potencial (\versal{GILLESPIE}, 2010).

Visto que as mídias sociais já são a principal fonte de informação de
grande parte da população conectada, nos últimos anos as pesquisas da
área de tecnologia e sociedade estão cada vez mais interessadas nos
algoritmos que controlam o fluxo de informação dentro dessas plataformas
(\versal{PARISER}, 2012). A mais utilizada pelos brasileiros, a Facebook,
armazena mais de 300 \emph{petabytes} de dados dos usuários
(\versal{JOLER}; \versal{PEtROVSKI}, 2016), essenciais para o trabalho de filtragem de informação que seus softwares exercem. A personalização do conteúdo recebido por cada usuário é vital
não apenas para permitir que eles recebam as postagens mais relevantes
(de acordo com os critérios de relevância da empresa), mas também para
atingir os objetivos do mercado publicitário, responsável por 92\% da
receita da empresa em 2014 (\versal{SILVEIRA}, 2017). Para uma análise bastante
detalhada do perfil de cada usuário, a empresa especializa"-se em
produzir novos softwares que possibilitam um monitoramento intenso do
comportamento, dos interesses e da comunicação de quem a utiliza.

Para Nick Srnicek (2016), estamos vivendo uma nova fase do capitalismo,
chamado de ``Capitalismo de Plataforma'', em que os dados são a
principal matéria prima e as plataformas o seu modelo de negócio.

\begin{quote}
No século \versal{XXI}, com base nas mudanças nas tecnologias digitais, os dados
se tornaram cada vez mais centrais para as empresas e suas relações com
os trabalhadores, clientes e outros capitalistas. A plataforma surgiu
como um novo modelo de negócios, capaz de extrair e controlar
quantidades imensas de dados, e com essa mudança vimos o aumento de
grandes empresas monopolistas. Hoje, o capitalismo das economias de
renda alta e média é cada vez mais dominado por essas empresas\footnote{\emph{``In
  the twenty"-first century, on the basis of changes in digital
  technologies, data have become increasingly central to firms and their
  relations with workers, customers, and other capitalists. The platform
  has emerged as a new business model, capable of extracting and
  controlling immense amounts of data, and with this shift we have seen
  the rise of large monopolistic firms. Today the capitalism of the high
  and middle"-income economies is increasingly dominated by these
  firms''}.} (\versal{SRNICEK}, 2016, p. 12, tradução nossa).
\end{quote}

O autor define plataforma como ``infraestruturas digitais, que permitem
que dois ou mais grupos interajam''\footnote{``\emph{Digital infrastructures
  that enable two or more groups to Interact}''.} (\emph{Ibid}., p. 31, tradução
nossa). Elas posicionam"-se como intermediárias que reúnem tipos
diferentes de usuários, como ``clientes, anunciantes, provedores de
serviços, produtores, fornecedores e até objetos físicos''\footnote{\emph{``Customers,
  advertisers, service providers, producers, suppliers, and even
  physical objects}''.} (\emph{Ibid}., p. 31, tradução nossa) e possuem a vantagem
de operarem em qualquer lugar onde ocorra interação digital. Plataformas
de publicidade, como o Google e o Facebook, marcam as primeiras
tentativas de criar um modelo de negócio que se adequasse à era digital.
Elas acompanharam a popularização da web e se apropriaram da narrativa
da internet como ferramenta para democratizar a comunicação e acabar com
o monopólio dos jornais e outras mídias de massa sobre o que era
expressado na sociedade (\versal{SRNICEK}, 2016). Atualmente, apesar de negar o
status de monopólio, empresas como o Facebook demonstram dificuldades em
apontar concorrentes diretos (\versal{JEONG}, 2018).

Shoshana Zuboff (2015) possui um entendimento parecido, mas insere nesse
contexto a possibilidade de modificação de comportamento que as
plataformas trazem. Ela define esse sistema econômico contemporâneo, que
possui em sua centralidade técnicas como \emph{data mining} e
\emph{profiling}, como Capitalismo de Vigilância: ``uma nova forma de
capitalismo informacional que visa prever e modificar o comportamento
humano como forma de produzir receita e controle de mercado'' (p. 75). O
Google é visto como pioneiro nessa forma de extrair valor da coleta e
análise massiva de dados com intuito preditivo e performativo, e seu
modelo de negócio é a base do sistema econômico descrito por Zuboff. Ao
pensar no funcionamento do buscador, apenas um dos serviços da empresa,
onde centenas de dados dos usuários são analisados de forma que é
possível criar um perfil de identificação única de cada usuário e prever
o seu comportamento com base em comportamentos prévios e correlações,
para assim entregar a ele uma fórmula de resultados de busca certeiros
-- tanto para os anunciantes, quanto para os desejos e necessidades do
usuário -- a autora mostra que a propriedade dos meios de modificação do
comportamento é hoje uma forma de poder equivalente, ou superior, à
propriedade dos meios de produção (\versal{ZUBOFF}, 2015).

Ao tratarmos da coleta massiva de dados como parte central do modelo de
negócio dessas plataformas, é importante lembrar que esse tipo de
monitoramento, apesar de servir também para fortalecer parcerias com
governos e vigiar ações ilegais ou mesmo acompanhar ativistas e
movimentos sociais, não se preocupa com indivíduos identificáveis, mas
sim com perfis. O perfil pode ser descrito como ``um conjunto de traços
que não concerne a um indivíduo específico, mas sim expressa relações
entre indivíduos, sendo mais interpessoal do que intrapessoal'' (\versal{BRUNO}, p.
161). Para Fernanda Bruno, os perfis são simulações de identidades e
padrões estimativos que antecipam potencialidades ­-- sejam elas de
consumo, econômicas, comportamentais, entre outras. Assim o principal
objetivo para a sua criação é ``usar um conjunto de informações pessoais
para agir sobre similares'' (\emph{Ibid}.) e orientar um comportamento futuro.
Ela explica que ``a inadequação ao perfil não representa um desvio, mas
uma contingência, uma particularidade a ser não corrigida, mas
incorporada aos próprios cálculos futuros de definição de
perfil''(\emph{Ibid}.).

Antoinette Rouvroy e Thomas Berns (2015) descrevem essas práticas
(\emph{profiling} e \emph{data mining}) como um tipo de
governamentalidade algorítmica, que trabalha com correlações e não com a
norma, em que todo comportamento é abstraído do contexto no qual
apareceu e reduzido a dado. Nesse caso, é a própria correlação que dá
sentido a esses dados. Assim, o saber produzido no nível da elaboração
de perfil é pouco disponível ou perceptível pelos indivíduos sujeitos a
essa ação. Essa ofuscação é intencional e serve para tornar a plataforma
um local onde as restrições que por lá existam não sejam de fato
sentidas e o ambiente continue propício para a ação. Não há dúvidas de
que cada plataforma possui suas próprias visões de comportamentos
desejáveis e indesejáveis dos usuários que a utilizam, porém, ao invés
de conter certos movimentos, preferem tornar a ``desobediência (ou
certas formas de marginalidade) sempre mais improváveis (na medida em
que estas teriam sempre já sido antecipadas)'' (p. 41). A modulação é mais
vantajosa do que a restrição e a governamentalidade algorítmica, ``assim
como a segurança para Foucault, trataria"-se de assegurar as
circulações'' (p. 43).

Para Van Djick (2013), essas plataformas possibilitam um típico
específico de capital social, o da conectividade. Plataformas promovem e
invisibilizam, algoritmicamente, algumas informações em comparação a
outras. Elas fazem o mesmo com as conexões interpessoais dentro de suas
redes: algoritmos definem quais laços devem ser fortalecidos, e quais
serão enfraquecidos. Com isso, o nível de conectividade de cada usuário
é um dos fatores que define sua visibilidade nesses ambientes (\versal{ARAÚJO},
2017; \versal{JURNO}, 2015)). Plataformas como o Facebook, que possuem como
principal fonte de renda a mediação da entrega de publicidade, seguem
investindo em definir formas para quantificar o coeficiente de
influência de cada usuário, como mostra a patente US20170277691A1
(\versal{AGARWAL}, 2016). Com o título \emph{Quantifying Social Influence}, o
requerimento de patente refere"-se a uma tecnologia que permite analisar
os dados de interação de usuários em uma rede social online para
ranquear seu nível de influencia com base no conteúdo compartilhado pelo
mesmo e na interação de sua ``audiência'' com esse conteúdo, para assim
poder ``performar um tipo de ação com base no coeficiente de influência
social do usuário'' (\versal{AGARWAL}, 2016, tradução nossa, online).

Com base na ideia foucaultiana de que o poder está diretamente ligado à
produção de verdade e ao saber (\versal{FOUCAULT}, 2013),
é possível afirmar que as grandes plataformas de mídia social, como o
Facebook, possuem um saber e um poder enorme sobre os usuários que
interagem por meio delas. Esse poder só é possível a partir da coleta
massiva de dados possibilitada pelas tecnologias cibernéticas utilizadas
pela empresa, e o valioso saber que resulta dessas práticas é protegido
em seus bancos de dados (\versal{MORTENSON}, 2017) e em patentes registradas
(\versal{JOLER}; \versal{PETROVSKI}, 2016).

Alain Desrosières (2002), ao analisar a história do pensamento estatístico, que data dos séculos
\versal{XVII} e \versal{XVIII}, também se dedicou a estudar como uma forma de saber pode
se transformar em poder. Ao descrever o início da busca por cálculos
probabilísticos, o autor mostra que a questão que essa nova ciência
pretendia solucionar veio de uma tentativa antiga de encontrar algo que
possibilitasse especular sobre o que até então estava apenas na mão de
Deus, era sagrado: o acaso. ``Quer permitindo que ele decida casos
difíceis, ou integrando a avaliação de um futuro incerto no
presente''\footnote{``\emph{Either by allowing it to decide difficult cases,
  or by integrating the assessment of an uncertain fiiture into the
  present time}''.} (p. 46, tradução nossa). Assim, o autor compara o papel
do estatístico com o de um juiz.

O ato de classificar, valorizar e avaliar fenômenos naturais a nossa
volta não é algo novo. No entanto, uma característica que marca a nossa
época é o fato de realizarmos essas tarefas utilizando ``ferramentas
tecnológicas e virtuais compostas de algoritmos capazes de sintetizar,
processar e divulgar dados em uma velocidade e quantidade jamais
testemunhadas em nossa história'' (\versal{SARTORE}; \versal{LEITE}, 2017, p. 13). Para Bruno, uma nova racionalidade estatística estaria em curso.

\begin{quote}
Em ruptura com as ambições modernas da racionalidade dedutiva vinculando
os fenômenos observáveis (isto é, os fenômenos previamente selecionados
como objetos de observação e de análise em função de critérios de
interesse explícitos ou implícitos) a suas causas, a racionalidade
estatística segue uma lógica indutiva bem particular desde que ela tira
a sua força do tratamento automatizado de informações cuja única
qualidade é o aspecto massivo: indiferente às causas dos fenômenos, esta
racionalidade ancora"-se na observação puramente estatística de
correlações (independentes de toda lógica) entre dados coletados de uma
maneira absolutamente não seletiva numa variedade de contextos
heterogêneos (\versal{ROUVROY} e \versal{BERNS} \emph{apud}. \versal{BRUNO}, 2013, p. 159).
\end{quote}

Rouvroy e Berns (2015) pontuam que, diferentemente da estatística
moderna, esse novo modelo, com base em novas oportunidades de agregação
e análise massiva de dados parece emancipar"-se de toda relação à
``média'' ou ao ``normal'', como se ``apreendessem a realidade social
como tal, de maneira direta e imanente'' (2015, p. 37). Dado que a produção
de saber se dá a partir de informações não classificadas, heterogêneas,
dispensa"-se também a necessidade de verificar uma hipótese, solicitando
assim o mínimo de intervenção humana.

Visto que uma das características da sociedade informacional é que ela
se constitui com tecnologias que comunicam e controlam ao mesmo tempo
(\versal{SILVEIRA}, 2017), o controle é um tema importante ao discutirmos os
processos algorítmicos utilizados nas plataformas de mídias sociais.
Para Deleuze (1992), passamos da era das Sociedades Disciplinares,
conforme apresentadas por Foucault (2011), e estamos vivendo em uma Sociedade de Controle (\versal{DELEUZE}, 1992). Ele mostra que esse novo poder de controle não está tão
preocupado com dispositivos que confinem corpos e restrinjam seus
deslocamentos, como ilustrado pelo panóptico de Jeremy Bentham (\versal{FOUCAULT}, 2011).
A restrição agora passa para o campo da informação, possibilitando ou rejeitando seu acesso a ela.

\begin{quote}
As sociedades disciplinares têm dois polos: a assinatura que indica o
indivíduo, e o número de matrícula que indica sua posição na massa
(\ldots{}). Nas sociedades de controle, ao contrário, o essencial não é mais
uma assinatura e nem um número, mas uma cifra: a cifra é uma senha, ao
passo que as sociedades disciplinares são reguladas por palavras de
ordem (tanto do ponto de vista da integração quanto da resistência). A
linguagem numérica do controle é feita de cifras, que marcam o acesso à
informação, ou a rejeição. Não se está mais diante do par
massa"-indivíduo. Os indivíduos tornaram"-se ``dividuais'', divisíveis, e
as massas tornaram"-se amostras, dados, mercados ou ``bancos'' (\versal{DELEUZE},
1992, p. 226).
\end{quote}

Para Lazzarato (2006), as sociedades de controle ``se investem da memória mental, mais do que
da memória corporal'' (p. 84). Para ele, a característica central desse
tipo de sociedade é a multiplicação da oferta de mundos. Porém, de
mundos normalizados, que não se tratam de mundos possível ou do
acontecimento e onde a nossa liberdade se trata apenas de escolher
dentre os possíveis que outros conceberam. ``Ficamos sem o direito de
participar da construção dos mundos, de formular problemas e de inventar
soluções, a não ser no interior de alternativas já estabelecidas''
(\versal{LAZZARATO}, 2006, p. 101).
É por isso que temos a sensação ``de que, uma vez que tudo é possível
(desde que no âmbito das alternativas preestabelecidas), nada é mais
possível (a criação de algo novo)'' (\emph{Ibid}., p. 102).

É esse tipo de controle que consegue ao mesmo tempo restringir e passar
a sensação de liberdade que Deleuze (1992) chama de modulação.

\begin{quote}
Os confinamentos são moldes, distintas moldagens, mas os controles são
uma modulação, como uma moldagem auto"-deformante que mudasse
continuamente, a cada instante, ou como uma peneira cujas malhas
mudassem de um ponto a outro (\versal{DELEUZE}, 1992, p. 221).
\end{quote}

Lazzarato (2006), influenciado pelas obras de Deleuze, entende a
modulação como ``diagrama da flexibilidade da produção e da
subjetividade'' (p. 73). Ele a vê como um exercício de poder que também se
ocupa dos corpos, mas é principalmente a dimensão incorporal que está em
jogo. As marcas deixadas pelo controle distanciam"-se cada vez mais dos
corpos para fixarem"-se na mente. Nesse contexto, o medo da punição é
substituído por dispositivos de modulação de condutas em que as
tecnologias que controlam caminham junto à sensação de conforto,
resolvem problemas, melhoram a experiência do usuário, ``não geram medo,
mas afeto'' (\versal{SILVEIRA}, 2017, p. 83). Desta forma, a modulação já se tornou
fundamental para o marketing.

\begin{quote}
Depois da captura e armazenamento de dados para processamento e
mineração, as empresas formam amostras de perfis similares que servem
aos dispositivos de modulação. O que eles fazem? A partir dos gostos, do
temperamento, das necessidades, das possibilidades financeiras, do nível
educacional, entre outras sínteses, as empresas oferecem caminhos,
soluções, definições, produtos e serviços para suas amostras, ou seja,
para um conjunto potencial de consumidores que tiveram seus dados
tratados e analisados. O sucesso da modulação depende da análise precisa
das pessoas que serão moduladas (\versal{SILVEIRA}, 2017, p. 84).
\end{quote}

Uma das características da modulação é a possibilidade de criar um
espaço para o individual, dar a sensação de liberdade para o indivíduo
enquanto o mantém em um ambiente restrito (\versal{HUI}, 2015).
Foucault (1998), ao estudar o poder disciplinar, enxerga a liberdade como condição de
relações de poder. As dinâmicas de uso propostas pelas plataformas de
mídias sociais como o Facebook parecem potencializar o paradoxo da
liberdade controlada. Elas oferecem ambientes onde o usuário é
incentivado a compartilhar, mas só recebe a informação que uma série de
algoritmos decidiu ser mais relevante para ele. É incentivado a se
expressar, mas seguindo regras de conduta, ou escolhendo dentre seis
emoções que representem o que está sentindo.

Yuk Hui (2015) caracteriza esse novo tipo de controle, que Deleuze
(1992) chamou de modulação, pela possibilidade de ``criação de um espaço
para o indivíduo, como se ele ou ela tivesse a liberdade de se
entrelaçar e criar, enquanto sua produção, bem como seus fins, seguem a
lógica das forças intangíveis''\footnote{``\emph{Creating a space for the
  individual, as if he or she has the freedom to tangle and to create,
  while their production as well their ends follow the logic of
  intangible forces}'' (\emph{Ibid}., p. 95, tradução nossa).}

\begin{quote}
Devido à falta de regras rígidas (o que equivaleria à moldagem), o
sujeito concebido em termos de modulação e processos modulatórios parece
ter a liberdade de agir, mesmo que essa liberdade já seja antecipada por
sistemas reguladores, e os próprios atos são modulados de tal maneira
que assumem um caráter auto"-regulador\footnote{``\emph{Due to the lack of
  rigid regulations (which would equate with moulding), the subject
  conceived in terms of modulation and modulatory processes seems to
  have the freedom to act, even if such freedom is already anticipated
  by regulatory systems, and 84 New Formations the free acts themselves
  are modulated in such a way that they take on a selfregulatory
  character}''.}
 (\versal{HUI}, 2015, p. 83, tradução nossa).
\end{quote}

Para Hui (2015), a moldagem, característica do poder disciplinar, e a modulação não
possuem qualquer similaridade e são diferentes ``em termos de
significado metafísico e das implicações políticas''\footnote{``\emph{In terms
  of metaphysical meaning and political implications}'' (p. 84, tradução
nossa).} Já David Savat (2009) enxerga a modulação como uma amplificação do poder disciplinar. Nessa perspectiva, os mecanismo e instrumentos que Foucault identificou com
essenciais para seu funcionamento não deixaram de existir:

\begin{quote}
Na verdade, os modos de observação pelos quais a disciplina funciona
como uma forma de poder agora operam mais vigorosamente do que nunca,
seja através do uso de mídias sociais como Facebook, localização \versal{GPS} via
telefone celular, identificação por radiofrequência (\versal{RFID}) ou coleta de
dados do consumidor em nossas atividades do dia"-a"-dia\footnote{``\emph{In
  fact, the modes of observation by which discipline as a mode of power
  functions now operate more forcefully than ever, whether this be
  through the use of social media like Facebook, \versal{GPS} location via mobile
  phone, radiofrequency identification (\versal{RFID}), or the collection of
  consumer data in our day"-to"-day activities}''.} (\versal{SAVAT}, 2013, p. 222, tradução nossa). 
\end{quote}

Para o autor, essa amplificação surge, em grande parte, a partir da
extensão do dispositivo da escrita, em decorrência do uso de grandes
bancos de dados que armazenam nossos rastros digitais. Ao expandir esse
dispositivo ``estamos também potencialmente expandindo e, igualmente
significativamente, intensificando a função coercitiva da observação,
bem como a rede de relações que `produz poder'"\footnote{``\emph{We are
  thereby also potentially expanding, and, equally significantly,
  intensifying, the coercive function of observation as well as the
  network of relations that `produces power}'".}
(\versal{SAVAT}, 2013, p. 303, tradução nossa).
Dessa forma, a disciplina e a modulação podem ocorrer ao mesmo tempo e
utilizar mecanismos similares, em certas ocasiões. Como exemplo da
convergência dessas duas formas de poder, o autor cita o
compartilhamento de informações das redes sociais online com algumas
empresas.

\begin{quote}
Embora essas empresas possam não necessariamente coletar as informações
como parte de um mecanismo disciplinar, isso não significa que o olhar
disciplinar não se estenda a esses sites. Como uma série de incidentes
relatados na imprensa popular têm demonstrado, por vezes, esta
informação alimenta a máquina disciplinar - quando um empregador ou
empregador, descobre informações sobre um empregado, suas atividades ou
suas relações com os outros, que depois submete o indivíduo a
disciplina, tipicamente por meio de um mecanismo de punição em vez de um
mecanismo de recompense (\versal{SAVAT}, 2013, p. 305).
\end{quote}

Apesar do poder modulador não eliminar o poder disciplinar, ambos
produzem efeitos bem diferentes. Se por um lado o objeto que a
disciplina produz é o indivíduo, o produto da modulação não possui forma
e está sempre mudando, é mais um processo do que um objeto
(\versal{SAVAT}, 2013). Além disso, a modulação trabalha com uma forma diferente de
intervenção. Assim como Rouvroy e Berns (2015), Savat (2013) também
aponta que na disciplina há a necessidade de ter um indivíduo como alvo,
para poder corrigir seu comportamento. Já na modulação o objetivo é
antecipar o comportamento.

\begin{quote}
Com o surgimento de bancos de dados, no entanto, o foco é cada vez mais
na observação de um número de diferentes fatores abstratos a fim de
antecipar o surgimento de comportamentos desviantes (seja bom ou ruim)
de modo que isso possa ser prevenido antes mesmo que isso surja ou, se
bom (como a compra de um produto) seja incentivado\footnote{``\emph{With the
  emergence of databases, however, the focus is increasingly on
  observing a number of different abstract factors in order to
  anticipate the emergence of deviant behavior (whether good or bad) so
  that it can be prevented before it even arises or, if good (such as
  the purchase of a product) be encouraged}''.}
(\versal{SAVAT}, 2013, p. 391).
\end{quote}

A intenção de encontrar formas de modular o comportamento humano sem a
necessidade de restringir suas ações, mas concentrando"-se nas
construções de mundos e na mente, como descrito por Lazzarato (2006)
pode ser vista em alguns experimentos aplicados pelo Facebook ao longo
dos anos. Durante um estudo realizado por pesquisadores da empresa em
parceria com pesquisadores da Universidade de Cornell, em janeiro de
2012, as postagens recebidas por 689 mil usuários em seus News Feed
foram modificadas. O objetivo era descobrir se as emoções dos amigos
destes usuários, expressadas em seus posts na rede social, influenciava
o humor daqueles que as liam, causando uma espécie de ``contágio
emocional'', mesmo à distância (\versal{KRAMER}; \versal{GUILLORY}, \versal{HANCOCK}, 2014). Dois
grupos foram separados. Enquanto um tinha postagens com palavras
positivas como ``amo'' e ``legal'' filtradas e retiradas de seus News
Feed, o outro grupo deixava de receber postagens com palavras negativas
como ``ferido'' e ``nojento''. O estudo mostrou que pessoas que recebiam
menos postagens positivas também acabavam postando menos mensagens
positivas em suas próprias redes, confirmando a hipótese de que os
usuários ficam menos felizes após serem impactados por esse conjunto de
mensagens com poucas palavras positivas.

Nenhum dos 689 mil usuários foi informado que estava participando de um
estudo. A justificativa legal do Facebook é a de que ao assinar os
termos de uso da plataforma, todos os usuários aceitam participar de
pesquisas e ter seus dados analisados. Contudo, muitos pesquisadores
apontaram que esse não é o consentimento informado exigido pela The
Federal Policy for the Protection of Human Subjects, recurso ético e
legal exigido ao realizar pesquisar com sujeitos humanos (\versal{BOOTH}, 2014).

É importante lembrar que a exploração dos limites cognitivos de
consumidores pelas empresas de marketing não é uma decorrência da Web.
No entanto, não podemos negar que o uso de tecnologias cibernéticas e
algoritmos atrelados a grandes bases de dados, utilizados na mediação de
certas transações tornou possível a individualização e sistematização
dessas práticas (\versal{CALO}, 2014). O estudo de plataformas e sistemas
algorítmicos, em que decisões humanas e ações maquínicas emaranham"-se em
direção a objetivos específicos, seguindo modelos de negócio pouco
esclarecidos, mostra"-se uma tarefa complexa e desafiadora,
principalmente para aqueles que buscam esse conhecimento do lado de fora
das empresas que detêm essas tecnologias. Portanto, para contribuir com
o tópico e atravessar as caixas pretas, é necessária uma abordagem
interdisciplinar, que observe a rede de actantes que gerencia esses
sistemas, seus objetivos, as dinâmicas e consequências de suas escolhas
e a lógica que proporciona tais inovações tecnológicas.

\section{Referências}

\versal{ABBAS}, A.; \versal{ZHANG}, L.; \versal{KHAN}, S. U. \emph{A literature review on the
state"-of"-the"-art in patent analysis}. World Patent Information, 1 jun.
2014. v. 37, p. 3--13.

\versal{AGARWAL}, N. \emph{Quantifying Social Influence}. Disponível em:
\emph{https://bit.ly/2QyPQJO}. Acesso em: 11 set. 2018.

\versal{ARAÚJO}, W. F. \emph{As narrativas sobre os algoritmos do Facebook: uma
análise dos 10 anos do feed de notícias}. Porto Alegre: Faculdade de
Biblioteconomia e Comunicação, Universidade Federal do Rio Grande do
Sul, 2017. (Doutorado em Comunicação e Informação).

\versal{BOOTH}, R. \emph{Facebook reveals news feed experiment to control
emotions}. The Guardian, [S.l.], 29 jun. 2014. Disponível em:
\emph{https://bit.ly/1ofH8J7}. Acesso em: 11 set. 2018.

\versal{BRUNO}, F. \emph{Rastros digitais sob a perspectiva da teoria
ator-rede}. Revista \versal{FAMECOS}, 2012. v. 19, n. 3, p. 681--704.

\_\_\_\_\_\_. \emph{Máquinas de ver, modos de ser: vigilância,
tecnologia e subjetividade}. Porto Alegre: Editora Sulina, 2013.

\versal{CALISKAN}, A. \emph{et al.} \emph{Semantics derived automatically from
language corpora contain human-like biases}. Science, 17 abr. 2017. v.
356, p. 183--186.

\versal{CALO}, Ryan, \emph{Digital Market Manipulation}. 82 George Washington
Law Review 995, 16 ago. 2013. n. 2013-27, p. 995-2051. Disponível em:
\emph{https://bit.ly/2S3awqe}. Acesso em: 9 set. 2018.

\versal{CASTELLS}, M. \emph{A sociedade em rede}. São Paulo: Paz e Terra, 2007.

\versal{DAIM}, T. U. \emph{et al.} \emph{Forecasting emerging technologies: Use
of bibliometrics and patent analysis}. Technological Forecasting and
Social Change, out. 2006. v. 73, n. 8, p. 981--1012.

\versal{DELEUZE}, G. \emph{Conversações}. São Paulo: Editora 34, 1992.

\versal{DESROSIÈRES}, A. \emph{The Politics of Large Numbers: A History of
Statistical Reasoning}. Cambridge: Harvard University Press, 2002.

\versal{DONOHUE}, A. \emph{Augmenting text messages with emotion information}.
Disponível em: \emph{https://bit.ly/2rzO505}. Acesso em: 11 set. 2018.

\versal{DOURISH}, P. \emph{Algorithms and their others: Algorithmic culture in
context}. Big Data \& Society, 1 dez. 2016. v. 3, n. 2, p. 1--11.

\versal{FOUCAULT}, M. \emph{Historia Da Sexualidade, v. 2 -- O Uso Dos Prazeres}.
São Paulo: Paz e Terra, 1998.

\_\_\_\_\_\_. \emph{Vigiar e punir: nascimento da prisão}. Petropolis:
Vozes, 2011.

\_\_\_\_\_\_. \emph{A Verdade e as Formas Jurídicas}. Edição:
4ª ed. Rio de Janeiro: \versal{NAU}, 2013.

\versal{GILLESPIE}, T. \emph{The politics of `platforms'}. New Media \&
Society, 1 maio. 2010. v. 12, n. 3, p. 347--364.

\_\_\_\_\_\_. \emph{The Relevance of Algorithms}. \emph{In}:
\versal{GILLESPIE}, T.; \versal{BOCZKOWSKI}, P. J.; \versal{FOOT}, K. A. (Org.). \emph{Media
Technologies}. Cambridge: The \versal{MIT} Press, 2014, p. 167--194.

\versal{HILBERT}, M. \emph{Quantifying the Data Deluge and the Data Drought}.
Rochester, \versal{NY}: Social Science Research Network, 2015. Disponível em:
\emph{https://bit.ly/2QTu6I3}. Acesso em: 11 set. 2018.

\versal{HUI}, Y. \emph{Modulation after Control}. New formations: a journal of
culture/theory/politics, 7 nov. 2015. v. 84, n. 84, p. 74--91.

\versal{IFI CLAIMS}. 2017 \emph{Top 50 \versal{US} Patent Assignees}. \versal{IFI CLAIMS}® Patent
Services, 2018. Disponível em: \emph{https://bit.ly/2UL5JLx}. Acesso em: 11 set. 2018.

\versal{INTRONA}, L. D. \emph{Algorithms, Governance, and Governmentality: On
Governing Academic Writing}. Science, Technology, \& Human
Values, 1 jan. 2016. v. 41, n. 1, p. 17--49.

\versal{JEONG}, S. \emph{Zuckerberg struggles to name a single Facebook
competitor}. The Verge, 10 abr. 2018. Disponível em: \emph{https://bit.ly/2qmzeFm}. Acesso em: 11 set. 2018.

\versal{JOLER}, V.; \versal{PETROVSKI}, A. \emph{Immaterial Labour and Data Harvesting}.
\versal{SHARE LAB}, 21 ago. 2016. Disponível em: \emph{https://bit.ly/2csMIMs}. Acesso em: 11 set. 2018.

\versal{KITCHIN}, R. \emph{Thinking Critically About and Researching
Algorithms}. Rochester, \versal{NY}: Social Science Research Network, 2014.
Disponível em: \emph{https://bit.ly/2Gj5cxz}. Acesso em: 11 set. 2018.

\_\_\_\_\_\_. \emph{Thinking critically about and researching
algorithms}. Information, Communication \& Society, 2 jan. 2017. v. 20,
n. 1, p. 14--29.

\versal{KRAMER}, Adam; \versal{GUILLORY}, Jamie; \versal{HANCOCK}, Jeffrey. \emph{Experimental evidence of massive-scale emotional contagion through social networks}. \versal{PNAS}. vol.
111. 2014. Disponível em: \emph{https://bit.ly/1qEO2IX}.

\versal{LATOUR}, B. \emph{Science in Action: How to Follow Scientists and
Engineers Through Society}. Cambridge: Harvard University Press, 1987.

\versal{LAZZARATO}, M. \emph{As revoluções do capitalismo}. São Paulo: Editora
Record, 2006.

\versal{LEVY}, P. \emph{Cibercultura}. São Paulo: Editora 34, 2010.

\versal{MACHLUP}, F. \emph{The production and distribution of knowledge in the
United States}. 1. paperback ed. Princeton, \versal{NJ}: Princeton Univ.
Press, 1972.

\versal{MAHDAWI}, A. \emph{Uber developing technology that would tell if you're
drunk}. The Guardian, 11 jun. 2018. Disponível em: \emph{https://bit.ly/2HF7jHl}.
Acesso em: 11 set. 2018.

\versal{MARINHO}, M. H. \emph{O consumidor brasileiro agora é hiper}. Think
with Google, 2014. Disponível em: \emph{https://bit.ly/2SHVAO6}.
Acesso em: 11 set. 2018.

\versal{MORTENSON}, D. \emph{2017 Year in review: Data centers}. Facebook Code,
2017. Disponível em: \emph{https://bit.ly/2PSk8aj}. Acesso em: 11 set. 2018.

\versal{PARISER}, E. \emph{O filtro invisível: O que a internet está escondendo
de você}. Rio de Janeiro: Zahar, 2012.

\versal{PASQUALE}, F. \emph{The black box society: the secret algorithms that
control money and information}. Cambridge: Harvard University Press,
2015.

\versal{RIEDER}, B. \emph{Scrutinizing an algorithmic technique: the Bayes
classifier as interested reading of reality}. Information, Communication
\& Society, 2 jan. 2017. v. 20, n. 1, p. 100--117.

\versal{ROUVROY}, Antoinette; \versal{BERNS}, Thomas. \emph{Governamentalidade
algorítmica e perspectivas de emancipação: o díspar como condição de
individuação pela relação?}. Revista \versal{ECO}-Pós, [S.l.], v. 18, n. 2, p.
36-56, out. 2015. \versal{ISSN} 2175-8689. Disponível em:
\emph{https://bit.ly/2UH9rGl}. Acesso em: 11 Set. 2018.

\versal{SARTORE}, M. D. S.; \versal{LEITE}, E. D. S. \emph{Desconstruindo os
dispositivos dos mercados: aportes da Sociologia Econômica}. Revista
\versal{TOMO}, 29 jun. 2017. Disponível em: \emph{https://bit.ly/2rAX019}. Acesso em: 11 set. 2018.

\versal{SAVAT}, D. \emph{Deleuze and new technology}. Edinburgh: Edinburgh
University Press, 2009.

\versal{SEAVER}, N. \emph{Algorithms as culture: Some tactics for the
ethnography of algorithmic systems}. Big Data \& Society, 1 dez. 2017. v.
4, n. 2, p. 2053951717738104.

\versal{SILVEIRA}, S. A.; \versal{AVELINO}, R.; \versal{SOUZA}, J. \emph{A privacidade e o
mercado de dados pessoais} (\emph{Privacy and the market of personal
data}). Liinc em Revista, 30 nov. 2016. v. 12, n. 2. Disponível em:
\emph{https://bit.ly/2EyfJD2}. Acesso em: 11 set. 2018.

\versal{SILVEIRA}, S. A. da. \emph{Tudo sobre tod@s: Redes digitais,
privacidade e venda de dados pessoais}. São Paulo: Edições Sesc, 2017.

\versal{SOUZA}, J.; \versal{MACHADO}, D.; \versal{AVELINO}, R. \emph{Big Data, Vigilância e o
Mercado de Dados Pessoais na Saúde}. Santiago, 2018. p. 17.

\versal{SRNICEK}, N. \emph{Platform Capitalism}. 1 edition. Cambridge, \versal{UK}-Malden,
\versal{MA}: Polity, 2016.

\versal{ZUBOFF}, Shoshana. \emph{Big other: surveillance capitalism and the
prospects of an information civilization.} London: Journal of
Information Technology, 2015, 75--89. Disponível em: \emph{https://bit.ly/2zpWPdV}. Acesso em: 11 set. 2018.

